---
layout: default
title: tsfresh quick walk through (Part III)
parent: Time Series
grand_parent: Feature Engineering
nav_order: 3
---

##  Quick walk through of tsfresh with financial data (Part III) 

*tsfresh official document page:* [tsfresh](https://tsfresh.readthedocs.io/en/latest/index.html)

This notebook uses functions in tsfresh package to create features and select features on financial time series data.

<h3> functions in tsfresh package</h3>

* `roll_time_series` function: prepare financial time series data to the format of data that can be fed into `extract_features` function. [reference](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.utilities.html#tsfresh.utilities.dataframe_functions.roll_time_series)

* `extract_features` function: a function that generates hundreds of features from raw time series data. [reference](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html?highlight=extract_features#tsfresh.feature_extraction.extraction.extract_features)
  - list of features: [see here](https://tsfresh.readthedocs.io/en/latest/text/list_of_features.html)

* `feature_calculators` module:  it includes functions such as `abs_energy` and `absolute_sum_of_changes`. All the features that can be generated via `extract_features` function can be individually generated via functions in this module. [reference](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html?highlight=feature_calculators#module-tsfresh.feature_extraction.feature_calculators)

* `impute` function: impute missing values in generated features. [reference](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.utilities.html?highlight=impute#tsfresh.utilities.dataframe_functions.impute)

* `select_features` function:  select features of high importance to **y** (i.e. target variable). [reference](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_selection.html?highlight=select_features#tsfresh.feature_selection.selection.select_features)



<h3> outline of this notebook</h3>

1. download data from yahoo finance: download files of two tickers (`PFE` and `GSK`)
1. load raw csv file: combine two raw csv file into one pandas dataframe,  create `id` column, and sort the data by `Date` in ascending order. 
1. prepare data by `roll_time_series` and create features via `extract_features`. 
1. `impute` function and deal with missing value  
1. create y (the target variable) 
1. select features by `select_features` function
1. save data


***

<h4>1. download data from yahoo finance</h4>

In this notebook, I will use *Pfizer Inc. ([PFE](https://finance.yahoo.com/quote/PFE/history?p=PFE))* and *GlaxoSmithKline plc ([GSK](https://finance.yahoo.com/quote/GSK/history?p=GSK))* as example.

Here shows how to download historical stock price data from yahoo finance. The two downloaded files are named `PFE.csv` and `GSK.csv` by default.

![title](img/pfe_yahoo.png)

<h4>2. load raw csv file</h4>


The raw data downloaded from yahoo finance looks like the following screenshot. I will combine `PFE.csv` and `GSK.csv` into one pandas dataframe. 

![title](img/pfe_csv.png)


```python
import pandas as pd
```


```python
df1 = pd.read_csv('data/PFE.csv')
df1['id'] = 'PFE'
df1.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2009-01-02</td>
      <td>16.963947</td>
      <td>17.362429</td>
      <td>16.793169</td>
      <td>17.333965</td>
      <td>10.938112</td>
      <td>30274000</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2009-01-05</td>
      <td>17.457306</td>
      <td>17.533207</td>
      <td>16.963947</td>
      <td>17.229601</td>
      <td>10.872255</td>
      <td>44439200</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2009-01-06</td>
      <td>17.381405</td>
      <td>17.495256</td>
      <td>16.802656</td>
      <td>16.888046</td>
      <td>10.656727</td>
      <td>53984400</td>
      <td>PFE</td>
    </tr>
  </tbody>
</table>
</div>




```python
df2 = pd.read_csv('data/GSK.csv')
df2['id'] = 'GSK'
df2.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2009-01-02</td>
      <td>36.520000</td>
      <td>37.099998</td>
      <td>36.439999</td>
      <td>36.970001</td>
      <td>19.927216</td>
      <td>905400</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2009-01-05</td>
      <td>36.110001</td>
      <td>36.529999</td>
      <td>35.779999</td>
      <td>36.380001</td>
      <td>19.609205</td>
      <td>1563200</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2009-01-06</td>
      <td>36.880001</td>
      <td>38.000000</td>
      <td>36.270000</td>
      <td>37.759998</td>
      <td>20.353031</td>
      <td>2270600</td>
      <td>GSK</td>
    </tr>
  </tbody>
</table>
</div>




```python
df = pd.concat([df1, df2])
df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2009-01-02</td>
      <td>16.963947</td>
      <td>17.362429</td>
      <td>16.793169</td>
      <td>17.333965</td>
      <td>10.938112</td>
      <td>30274000</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2009-01-05</td>
      <td>17.457306</td>
      <td>17.533207</td>
      <td>16.963947</td>
      <td>17.229601</td>
      <td>10.872255</td>
      <td>44439200</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2009-01-06</td>
      <td>17.381405</td>
      <td>17.495256</td>
      <td>16.802656</td>
      <td>16.888046</td>
      <td>10.656727</td>
      <td>53984400</td>
      <td>PFE</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3017</th>
      <td>2020-12-28</td>
      <td>36.790001</td>
      <td>36.790001</td>
      <td>36.169998</td>
      <td>36.290001</td>
      <td>36.290001</td>
      <td>2876300</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>3018</th>
      <td>2020-12-29</td>
      <td>37.209999</td>
      <td>37.380001</td>
      <td>36.860001</td>
      <td>36.980000</td>
      <td>36.980000</td>
      <td>4666300</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>3019</th>
      <td>2020-12-30</td>
      <td>37.169998</td>
      <td>37.240002</td>
      <td>36.900002</td>
      <td>37.040001</td>
      <td>37.040001</td>
      <td>3071400</td>
      <td>GSK</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(df1.shape, df2.shape, df.shape)
```

    (3020, 8) (3020, 8) (6040, 8)
    


```python
del df1
del df2
```


```python
df.sort_values(by=['id', 'Date'], ascending=[True, True], inplace=True)
df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2009-01-02</td>
      <td>36.520000</td>
      <td>37.099998</td>
      <td>36.439999</td>
      <td>36.970001</td>
      <td>19.927216</td>
      <td>905400</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2009-01-05</td>
      <td>36.110001</td>
      <td>36.529999</td>
      <td>35.779999</td>
      <td>36.380001</td>
      <td>19.609205</td>
      <td>1563200</td>
      <td>GSK</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2009-01-06</td>
      <td>36.880001</td>
      <td>38.000000</td>
      <td>36.270000</td>
      <td>37.759998</td>
      <td>20.353031</td>
      <td>2270600</td>
      <td>GSK</td>
    </tr>
  </tbody>
</table>
</div>




```python
df.tail(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Date</th>
      <th>Open</th>
      <th>High</th>
      <th>Low</th>
      <th>Close</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>id</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>3017</th>
      <td>2020-12-28</td>
      <td>37.360001</td>
      <td>37.580002</td>
      <td>36.680000</td>
      <td>36.820000</td>
      <td>36.820000</td>
      <td>26993700</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>3018</th>
      <td>2020-12-29</td>
      <td>36.900002</td>
      <td>37.200001</td>
      <td>36.790001</td>
      <td>37.049999</td>
      <td>37.049999</td>
      <td>23152100</td>
      <td>PFE</td>
    </tr>
    <tr>
      <th>3019</th>
      <td>2020-12-30</td>
      <td>37.029999</td>
      <td>37.240002</td>
      <td>36.700001</td>
      <td>36.740002</td>
      <td>36.740002</td>
      <td>24837900</td>
      <td>PFE</td>
    </tr>
  </tbody>
</table>
</div>




```python
sel_cols = ['id', 'Date', 'Adj Close', 'Volume']
df = df[sel_cols].copy(deep=True)
```


```python
df.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>19.927216</td>
      <td>905400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>19.609205</td>
      <td>1563200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GSK</td>
      <td>2009-01-06</td>
      <td>20.353031</td>
      <td>2270600</td>
    </tr>
  </tbody>
</table>
</div>



<h4>3. prepare data by `roll_time_series` and create features via `extract_features`</h4>

use `roll_time_series` function to prepare the data: this function convert the data int the following format so it can be consumed by `extract_features` function. 

key parameters of:`roll_time_series`
 
1. column_id: use `id` column
1. column_sort: use `Date` column
1. max_timeshift: set as 21 (the function will roll 22 rows). This parameter can be set as any integer between 1 to the number of rows in the raw dataframe. I set it as 21 to get features that capture the patterns in the past 30 days (~ 22 business days).
1. min_timeshift: set as 21. This parameter must be a number no larger than `max_timeshift`. When it is set to less than `max_timeshift`, the `roll_time_series` will roll the data - for the initial few rows of each `id` - starting from the row where there are `min_timeshift` of rows to roll. I set this number same as `max_timeshift`. 
1. rolling_direction: default value is `1`. if set as `-1` the rolling will be the reverse order.

`roll_time_series` transforms data in the following format. This function will duplicate rows and increase number of rows to (`original_rows_count` - 21x`number of unique id`)x22 (i.e. `(6040 - 21x2)x22 = 131956`)

![title](img/roll_data.png)


`extract_features` will turn the dataframe back to `original_rows_count - 21 x number of unique id` rows. 


```python
from tsfresh.utilities.dataframe_functions import roll_time_series
from tsfresh import extract_features
```


```python
roll_rows = 21
df_rolled = roll_time_series(df, column_id="id", column_sort="Date", max_timeshift=roll_rows, min_timeshift=roll_rows, disable_progressbar=True)
df_features = extract_features(df_rolled, column_id="id", column_sort="Date")
```

    Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 20/20 [03:04<00:00,  9.24s/it]
    


```python
print(df.shape, df_rolled.shape, df_features.shape, df_features.shape[0]-df.shape[0])
```

    (6040, 4) (131956, 4) (5998, 1558) -42
    


```python
df_rolled.head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(GSK, 2009-02-03)</td>
      <td>2009-01-02</td>
      <td>19.927216</td>
      <td>905400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(GSK, 2009-02-03)</td>
      <td>2009-01-05</td>
      <td>19.609205</td>
      <td>1563200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(GSK, 2009-02-03)</td>
      <td>2009-01-06</td>
      <td>20.353031</td>
      <td>2270600</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_rolled[df_rolled['Date']=='2009-02-03']
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21</th>
      <td>(GSK, 2009-02-03)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>64</th>
      <td>(GSK, 2009-02-04)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>107</th>
      <td>(GSK, 2009-02-05)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>150</th>
      <td>(GSK, 2009-02-06)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>193</th>
      <td>(GSK, 2009-02-09)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>236</th>
      <td>(GSK, 2009-02-10)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>279</th>
      <td>(GSK, 2009-02-11)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>322</th>
      <td>(GSK, 2009-02-12)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>365</th>
      <td>(GSK, 2009-02-13)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>408</th>
      <td>(GSK, 2009-02-17)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>451</th>
      <td>(GSK, 2009-02-18)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>494</th>
      <td>(GSK, 2009-02-19)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>537</th>
      <td>(GSK, 2009-02-20)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>580</th>
      <td>(GSK, 2009-02-23)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>623</th>
      <td>(GSK, 2009-02-24)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>666</th>
      <td>(GSK, 2009-02-25)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>709</th>
      <td>(GSK, 2009-02-26)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>752</th>
      <td>(GSK, 2009-02-27)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>795</th>
      <td>(GSK, 2009-03-02)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>838</th>
      <td>(GSK, 2009-03-03)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>881</th>
      <td>(GSK, 2009-03-04)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>924</th>
      <td>(GSK, 2009-03-05)</td>
      <td>2009-02-03</td>
      <td>19.593031</td>
      <td>1350600</td>
    </tr>
    <tr>
      <th>43</th>
      <td>(PFE, 2009-02-03)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>86</th>
      <td>(PFE, 2009-02-04)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>129</th>
      <td>(PFE, 2009-02-05)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>172</th>
      <td>(PFE, 2009-02-06)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>215</th>
      <td>(PFE, 2009-02-09)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>258</th>
      <td>(PFE, 2009-02-10)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>301</th>
      <td>(PFE, 2009-02-11)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>344</th>
      <td>(PFE, 2009-02-12)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>387</th>
      <td>(PFE, 2009-02-13)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>430</th>
      <td>(PFE, 2009-02-17)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>473</th>
      <td>(PFE, 2009-02-18)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>516</th>
      <td>(PFE, 2009-02-19)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>559</th>
      <td>(PFE, 2009-02-20)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>602</th>
      <td>(PFE, 2009-02-23)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>645</th>
      <td>(PFE, 2009-02-24)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>688</th>
      <td>(PFE, 2009-02-25)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>731</th>
      <td>(PFE, 2009-02-26)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>774</th>
      <td>(PFE, 2009-02-27)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>817</th>
      <td>(PFE, 2009-03-02)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>860</th>
      <td>(PFE, 2009-03-03)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>903</th>
      <td>(PFE, 2009-03-04)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
    <tr>
      <th>946</th>
      <td>(PFE, 2009-03-05)</td>
      <td>2009-02-03</td>
      <td>9.100128</td>
      <td>66814700</td>
    </tr>
  </tbody>
</table>
</div>



<h4>4. `impute` function and deal with missing value  </h4>

I will first remove features (i.e. columns) with more than 10% of data missing, and then deal with the remaining features.

The `impute` function replaces all `NaNs` and `infs` inplace.  Note this function only accepts numeric features and errors will be triggered if the dataframe passed to this function has non-numeric columns.


```python
df_features.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>Adj Close__has_duplicate</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__abs_energy</th>
      <th>Adj Close__mean_abs_change</th>
      <th>Adj Close__mean_change</th>
      <th>Adj Close__mean_second_derivative_central</th>
      <th>Adj Close__median</th>
      <th>...</th>
      <th>Volume__fourier_entropy__bins_2</th>
      <th>Volume__fourier_entropy__bins_3</th>
      <th>Volume__fourier_entropy__bins_5</th>
      <th>Volume__fourier_entropy__bins_10</th>
      <th>Volume__fourier_entropy__bins_100</th>
      <th>Volume__permutation_entropy__dimension_3__tau_1</th>
      <th>Volume__permutation_entropy__dimension_4__tau_1</th>
      <th>Volume__permutation_entropy__dimension_5__tau_1</th>
      <th>Volume__permutation_entropy__dimension_6__tau_1</th>
      <th>Volume__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="2" valign="top">GSK</th>
      <th>2009-02-03</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.952223</td>
      <td>8494.084498</td>
      <td>0.359854</td>
      <td>-0.015914</td>
      <td>0.024660</td>
      <td>19.601118</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.286836</td>
      <td>0.823959</td>
      <td>1.424130</td>
      <td>2.369382</td>
      <td>1.692281</td>
      <td>2.260234</td>
      <td>2.707270</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>2009-02-04</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.763572</td>
      <td>8486.601509</td>
      <td>0.351641</td>
      <td>0.006160</td>
      <td>-0.014957</td>
      <td>19.601118</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.539654</td>
      <td>2.369382</td>
      <td>1.748067</td>
      <td>2.378620</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 1558 columns</p>
</div>




```python
na_cnt = df_features.isna().sum().sort_values(ascending=False)
na_cnt.head()
```




    Adj Close__fft_coefficient__attr_"abs"__coeff_47    5998
    Volume__fft_coefficient__attr_"real"__coeff_17      5998
    Volume__fft_coefficient__attr_"real"__coeff_26      5998
    Volume__fft_coefficient__attr_"real"__coeff_25      5998
    Volume__fft_coefficient__attr_"real"__coeff_24      5998
    dtype: int64




```python
ratio = 0.1
print(ratio*df_features.shape[0])
drop_cols = na_cnt[na_cnt>ratio*df_features.shape[0]].index.tolist()
print('before dropping columns: ', df_features.shape)
df_features.drop(columns=drop_cols, inplace=True)
print('after dropping columns: ', df_features.shape)
```

    599.8000000000001
    before dropping columns:  (5998, 1558)
    after dropping columns:  (5998, 815)
    


```python
na_cnt = df_features.isna().sum().sort_values(ascending=False)
na_cnt.head()
```




    Volume__sample_entropy                                245
    Adj Close__sample_entropy                             180
    Volume__max_langevin_fixed_point__m_3__r_30            18
    Volume__friedrich_coefficients__coeff_3__m_3__r_30     18
    Volume__friedrich_coefficients__coeff_2__m_3__r_30     18
    dtype: int64




```python
from tsfresh.utilities.dataframe_functions import impute
```


```python
impute(df_features)
na_cnt = df_features.isna().sum().sort_values(ascending=False)
na_cnt.head()
```




    Volume__permutation_entropy__dimension_7__tau_1     0
    Adj Close__fft_coefficient__attr_"real"__coeff_4    0
    Adj Close__fft_coefficient__attr_"imag"__coeff_2    0
    Adj Close__fft_coefficient__attr_"imag"__coeff_1    0
    Adj Close__fft_coefficient__attr_"imag"__coeff_0    0
    dtype: int64




```python
df_features.reset_index(inplace=True)
df_features.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>level_0</th>
      <th>level_1</th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>Adj Close__has_duplicate</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__abs_energy</th>
      <th>Adj Close__mean_abs_change</th>
      <th>Adj Close__mean_change</th>
      <th>...</th>
      <th>Volume__fourier_entropy__bins_2</th>
      <th>Volume__fourier_entropy__bins_3</th>
      <th>Volume__fourier_entropy__bins_5</th>
      <th>Volume__fourier_entropy__bins_10</th>
      <th>Volume__fourier_entropy__bins_100</th>
      <th>Volume__permutation_entropy__dimension_3__tau_1</th>
      <th>Volume__permutation_entropy__dimension_4__tau_1</th>
      <th>Volume__permutation_entropy__dimension_5__tau_1</th>
      <th>Volume__permutation_entropy__dimension_6__tau_1</th>
      <th>Volume__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-02-03</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.952223</td>
      <td>8494.084498</td>
      <td>0.359854</td>
      <td>-0.015914</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.286836</td>
      <td>0.823959</td>
      <td>1.424130</td>
      <td>2.369382</td>
      <td>1.692281</td>
      <td>2.260234</td>
      <td>2.707270</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-02-04</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.763572</td>
      <td>8486.601509</td>
      <td>0.351641</td>
      <td>0.006160</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.539654</td>
      <td>2.369382</td>
      <td>1.748067</td>
      <td>2.378620</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 817 columns</p>
</div>




```python
df_features.rename(columns={'level_0':'id', 'level_1':'Date'}, inplace=True)
df_features.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>Adj Close__has_duplicate</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__abs_energy</th>
      <th>Adj Close__mean_abs_change</th>
      <th>Adj Close__mean_change</th>
      <th>...</th>
      <th>Volume__fourier_entropy__bins_2</th>
      <th>Volume__fourier_entropy__bins_3</th>
      <th>Volume__fourier_entropy__bins_5</th>
      <th>Volume__fourier_entropy__bins_10</th>
      <th>Volume__fourier_entropy__bins_100</th>
      <th>Volume__permutation_entropy__dimension_3__tau_1</th>
      <th>Volume__permutation_entropy__dimension_4__tau_1</th>
      <th>Volume__permutation_entropy__dimension_5__tau_1</th>
      <th>Volume__permutation_entropy__dimension_6__tau_1</th>
      <th>Volume__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-02-03</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.952223</td>
      <td>8494.084498</td>
      <td>0.359854</td>
      <td>-0.015914</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.286836</td>
      <td>0.823959</td>
      <td>1.424130</td>
      <td>2.369382</td>
      <td>1.692281</td>
      <td>2.260234</td>
      <td>2.707270</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-02-04</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.763572</td>
      <td>8486.601509</td>
      <td>0.351641</td>
      <td>0.006160</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.539654</td>
      <td>2.369382</td>
      <td>1.748067</td>
      <td>2.378620</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
  </tbody>
</table>
<p>2 rows × 817 columns</p>
</div>



<h4>5. create y (the target variable) </h4>

Target variable: a binary variable to indicate if the maximum of 'Adj Close' in the next 30 business days is no less than 4% higher than current date's 'Adj Close'.

**Steps to engineer the target variable:**

1. calculate the maximum `Adj Close` in the next 30 rows (data sorted by `Date` in ascending order).
    - denote the maximum `Adj Close` in the next 30 rows as `max_adj_close_30`
    - denote the current date's `Adj Close` as `current_close`
1. calculate the % change of maximum value compared to current date's value. 
    - denote the % change as `delta_pct`
    - `delta_pct = (max_adj_close_30 - current_close)/current_close*100`
1. convert the % change to a binary value
    - denote the target variable as `target`
    - if `delta_pct >=5`, then the `target=1`, else `target=0`


```python
df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>19.927216</td>
      <td>905400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>19.609205</td>
      <td>1563200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GSK</td>
      <td>2009-01-06</td>
      <td>20.353031</td>
      <td>2270600</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GSK</td>
      <td>2009-01-07</td>
      <td>20.778858</td>
      <td>1621000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>GSK</td>
      <td>2009-01-08</td>
      <td>21.150766</td>
      <td>1837100</td>
    </tr>
  </tbody>
</table>
</div>




```python
roll_rows = 30
df_rolled2 = roll_time_series(df, column_id="id", column_sort="Date", 
                             max_timeshift=roll_rows, min_timeshift=roll_rows, 
                              rolling_direction=-1, disable_progressbar=True)
```


```python
df_rolled2.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>(GSK, 2009-01-02)</td>
      <td>2009-01-02</td>
      <td>19.927216</td>
      <td>905400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>(GSK, 2009-01-02)</td>
      <td>2009-01-05</td>
      <td>19.609205</td>
      <td>1563200</td>
    </tr>
    <tr>
      <th>2</th>
      <td>(GSK, 2009-01-02)</td>
      <td>2009-01-06</td>
      <td>20.353031</td>
      <td>2270600</td>
    </tr>
    <tr>
      <th>3</th>
      <td>(GSK, 2009-01-02)</td>
      <td>2009-01-07</td>
      <td>20.778858</td>
      <td>1621000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>(GSK, 2009-01-02)</td>
      <td>2009-01-08</td>
      <td>21.150766</td>
      <td>1837100</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_features2 = extract_features(df_rolled2, column_id="id", column_sort="Date", column_value = 'Adj Close')
```

    Feature Extraction: 100%|██████████████████████████████████████████████████████████████| 20/20 [01:41<00:00,  5.09s/it]
    


```python
df_features2.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>Adj Close__has_duplicate</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__abs_energy</th>
      <th>Adj Close__mean_abs_change</th>
      <th>Adj Close__mean_change</th>
      <th>Adj Close__mean_second_derivative_central</th>
      <th>Adj Close__median</th>
      <th>...</th>
      <th>Adj Close__fourier_entropy__bins_2</th>
      <th>Adj Close__fourier_entropy__bins_3</th>
      <th>Adj Close__fourier_entropy__bins_5</th>
      <th>Adj Close__fourier_entropy__bins_10</th>
      <th>Adj Close__fourier_entropy__bins_100</th>
      <th>Adj Close__permutation_entropy__dimension_3__tau_1</th>
      <th>Adj Close__permutation_entropy__dimension_4__tau_1</th>
      <th>Adj Close__permutation_entropy__dimension_5__tau_1</th>
      <th>Adj Close__permutation_entropy__dimension_6__tau_1</th>
      <th>Adj Close__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="5" valign="top">GSK</th>
      <th>2009-01-02</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>607.464175</td>
      <td>11919.455113</td>
      <td>0.332559</td>
      <td>-0.055507</td>
      <td>-0.009214</td>
      <td>19.609205</td>
      <td>...</td>
      <td>0.376770</td>
      <td>0.463414</td>
      <td>0.822265</td>
      <td>1.037392</td>
      <td>2.014036</td>
      <td>1.523876</td>
      <td>2.224925</td>
      <td>2.617929</td>
      <td>2.991501</td>
      <td>3.163424</td>
    </tr>
    <tr>
      <th>2009-01-05</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
      <td>605.941029</td>
      <td>11861.070968</td>
      <td>0.326694</td>
      <td>-0.040171</td>
      <td>-0.010375</td>
      <td>19.593031</td>
      <td>...</td>
      <td>0.376770</td>
      <td>0.376770</td>
      <td>0.831403</td>
      <td>1.127483</td>
      <td>2.100679</td>
      <td>1.523876</td>
      <td>2.243613</td>
      <td>2.637309</td>
      <td>2.991501</td>
      <td>3.163424</td>
    </tr>
    <tr>
      <th>2009-01-06</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>604.539174</td>
      <td>11808.057642</td>
      <td>0.308457</td>
      <td>-0.071523</td>
      <td>-0.010734</td>
      <td>19.474447</td>
      <td>...</td>
      <td>0.376770</td>
      <td>0.376770</td>
      <td>0.831403</td>
      <td>1.276720</td>
      <td>2.133382</td>
      <td>1.551250</td>
      <td>2.262300</td>
      <td>2.637309</td>
      <td>2.938182</td>
      <td>3.107972</td>
    </tr>
    <tr>
      <th>2009-01-07</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>601.972734</td>
      <td>11710.174590</td>
      <td>0.308289</td>
      <td>-0.099742</td>
      <td>-0.013667</td>
      <td>19.398584</td>
      <td>...</td>
      <td>0.376770</td>
      <td>0.463414</td>
      <td>0.822265</td>
      <td>1.160186</td>
      <td>2.393312</td>
      <td>1.513303</td>
      <td>2.262300</td>
      <td>2.585965</td>
      <td>2.884863</td>
      <td>3.052521</td>
    </tr>
    <tr>
      <th>2009-01-08</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>598.630745</td>
      <td>11582.458051</td>
      <td>0.307549</td>
      <td>-0.123797</td>
      <td>-0.002870</td>
      <td>19.305689</td>
      <td>...</td>
      <td>0.233792</td>
      <td>0.463414</td>
      <td>0.702919</td>
      <td>1.160186</td>
      <td>2.166085</td>
      <td>1.452462</td>
      <td>2.142622</td>
      <td>2.534620</td>
      <td>2.831544</td>
      <td>2.997069</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 779 columns</p>
</div>




```python
sel_cols = ['Adj Close__maximum']
df_target = df_features2[sel_cols].copy(deep=True)
```


```python
df_target.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Adj Close__maximum</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="10" valign="top">GSK</th>
      <th>2009-01-02</th>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-05</th>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-06</th>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-07</th>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-08</th>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-09</th>
      <td>20.967508</td>
    </tr>
    <tr>
      <th>2009-01-12</th>
      <td>20.730349</td>
    </tr>
    <tr>
      <th>2009-01-13</th>
      <td>20.185947</td>
    </tr>
    <tr>
      <th>2009-01-14</th>
      <td>20.137426</td>
    </tr>
    <tr>
      <th>2009-01-15</th>
      <td>20.137426</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_target['max_adj_close_30'] = df_target['Adj Close__maximum'].shift(-1)
```


```python
df_target.head(10)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Adj Close__maximum</th>
      <th>max_adj_close_30</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th rowspan="10" valign="top">GSK</th>
      <th>2009-01-02</th>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-05</th>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-06</th>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-07</th>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>2009-01-08</th>
      <td>21.150766</td>
      <td>20.967508</td>
    </tr>
    <tr>
      <th>2009-01-09</th>
      <td>20.967508</td>
      <td>20.730349</td>
    </tr>
    <tr>
      <th>2009-01-12</th>
      <td>20.730349</td>
      <td>20.185947</td>
    </tr>
    <tr>
      <th>2009-01-13</th>
      <td>20.185947</td>
      <td>20.137426</td>
    </tr>
    <tr>
      <th>2009-01-14</th>
      <td>20.137426</td>
      <td>20.137426</td>
    </tr>
    <tr>
      <th>2009-01-15</th>
      <td>20.137426</td>
      <td>20.137426</td>
    </tr>
  </tbody>
</table>
</div>




```python
for i in range(0,10):
    print(df.iloc[i,1], df.iloc[i:(30+i),]['Adj Close'].max())
```

    2009-01-02 21.150766
    2009-01-05 21.150766
    2009-01-06 21.150766
    2009-01-07 21.150766
    2009-01-08 21.150766
    2009-01-09 20.967508
    2009-01-12 20.730349
    2009-01-13 20.185947
    2009-01-14 20.137426
    2009-01-15 20.137426
    


```python
df_target.reset_index(inplace=True)
df_target.rename(columns={'level_0':'id', 'level_1':'Date'}, inplace=True)
df_target.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close__maximum</th>
      <th>max_adj_close_30</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>21.150766</td>
      <td>21.150766</td>
    </tr>
  </tbody>
</table>
</div>




```python
print(df_target.shape, df.shape)
df_target = df_target.merge(df, on=['id', 'Date'], how='inner')
print(df_target.shape, df.shape)
df_target.head(2)
```

    (5980, 4) (6040, 4)
    (5980, 6) (6040, 4)
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close__maximum</th>
      <th>max_adj_close_30</th>
      <th>Adj Close</th>
      <th>Volume</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.927216</td>
      <td>905400</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.609205</td>
      <td>1563200</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_target['delta_pct'] = (df_target['max_adj_close_30'] - df_target['Adj Close'] )/df_target['Adj Close'] *100
df_target.head(2)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close__maximum</th>
      <th>max_adj_close_30</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>delta_pct</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.927216</td>
      <td>905400</td>
      <td>6.140095</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.609205</td>
      <td>1563200</td>
      <td>7.861415</td>
    </tr>
  </tbody>
</table>
</div>




```python
df_target['target'] = 0
df_target.loc[df_target['delta_pct']>=5, 'target'] = 1
df_target['target'].value_counts()
```




    0    3506
    1    2474
    Name: target, dtype: int64




```python
df_target.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>Adj Close__maximum</th>
      <th>max_adj_close_30</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>delta_pct</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-01-02</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.927216</td>
      <td>905400</td>
      <td>6.140095</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-01-05</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>19.609205</td>
      <td>1563200</td>
      <td>7.861415</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GSK</td>
      <td>2009-01-06</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>20.353031</td>
      <td>2270600</td>
      <td>3.919490</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GSK</td>
      <td>2009-01-07</td>
      <td>21.150766</td>
      <td>21.150766</td>
      <td>20.778858</td>
      <td>1621000</td>
      <td>1.789838</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>GSK</td>
      <td>2009-01-08</td>
      <td>21.150766</td>
      <td>20.967508</td>
      <td>21.150766</td>
      <td>1837100</td>
      <td>-0.866437</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



<h4>6. select features by `select_features` function </h4>

select_features(X, y, test_for_binary_target_binary_feature='fisher', test_for_binary_target_real_feature='mann', test_for_real_target_binary_feature='mann', test_for_real_target_real_feature='kendall', fdr_level=0.05, hypotheses_independent=False, n_jobs=1, show_warnings=False, chunksize=None, ml_task='auto', multiclass=False, n_significant=1)


```python
from tsfresh.feature_selection.selection import select_features
```


```python
df_target.columns
```




    Index(['id', 'Date', 'Adj Close__maximum', 'max_adj_close_30', 'Adj Close',
           'Volume', 'delta_pct', 'target'],
          dtype='object')




```python
sel_cols = ['id', 'Date', 'target', 'max_adj_close_30', 'delta_pct', 'Adj Close','Volume']
```


```python
#combine features with target variable
print(df_target.shape, df_features.shape)
df_final = df_target[sel_cols].merge(df_features, on = ['id', 'Date'], how='inner')
print(df_final.shape, df_target.shape, df_features.shape)
```

    (5980, 8) (5998, 817)
    (5938, 822) (5980, 8) (5998, 817)
    


```python
df_final.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>target</th>
      <th>max_adj_close_30</th>
      <th>delta_pct</th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>...</th>
      <th>Volume__fourier_entropy__bins_2</th>
      <th>Volume__fourier_entropy__bins_3</th>
      <th>Volume__fourier_entropy__bins_5</th>
      <th>Volume__fourier_entropy__bins_10</th>
      <th>Volume__fourier_entropy__bins_100</th>
      <th>Volume__permutation_entropy__dimension_3__tau_1</th>
      <th>Volume__permutation_entropy__dimension_4__tau_1</th>
      <th>Volume__permutation_entropy__dimension_5__tau_1</th>
      <th>Volume__permutation_entropy__dimension_6__tau_1</th>
      <th>Volume__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-02-03</td>
      <td>0</td>
      <td>20.137426</td>
      <td>2.778513</td>
      <td>19.593031</td>
      <td>1350600</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.286836</td>
      <td>0.823959</td>
      <td>1.424130</td>
      <td>2.369382</td>
      <td>1.692281</td>
      <td>2.260234</td>
      <td>2.707270</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-02-04</td>
      <td>0</td>
      <td>20.137426</td>
      <td>2.020719</td>
      <td>19.738565</td>
      <td>2432700</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.539654</td>
      <td>2.369382</td>
      <td>1.748067</td>
      <td>2.378620</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GSK</td>
      <td>2009-02-05</td>
      <td>0</td>
      <td>20.008068</td>
      <td>-0.642376</td>
      <td>20.137426</td>
      <td>3323300</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.450561</td>
      <td>0.721464</td>
      <td>1.098612</td>
      <td>1.539654</td>
      <td>2.484907</td>
      <td>1.735434</td>
      <td>2.406160</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GSK</td>
      <td>2009-02-06</td>
      <td>0</td>
      <td>19.937990</td>
      <td>-0.350249</td>
      <td>20.008068</td>
      <td>2266700</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.450561</td>
      <td>0.721464</td>
      <td>1.118743</td>
      <td>1.632631</td>
      <td>2.484907</td>
      <td>1.752424</td>
      <td>2.479122</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>4</th>
      <td>GSK</td>
      <td>2009-02-09</td>
      <td>0</td>
      <td>19.609205</td>
      <td>-1.649038</td>
      <td>19.937990</td>
      <td>1254900</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.473502</td>
      <td>2.253858</td>
      <td>1.752424</td>
      <td>2.506662</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 822 columns</p>
</div>




```python
df_final.isna().sum().sort_values(ascending=False).head(5)
```




    max_adj_close_30                                     1
    delta_pct                                            1
    Volume__permutation_entropy__dimension_7__tau_1      0
    Adj Close__fft_coefficient__attr_"real"__coeff_0     0
    Adj Close__fft_coefficient__attr_"real"__coeff_10    0
    dtype: int64




```python
print(df_final.shape)
df_final.dropna(how='any', inplace=True)
print(df_final.shape)
df_final.isna().sum().sort_values(ascending=False).head(5)
```

    (5938, 822)
    (5937, 822)
    




    Volume__permutation_entropy__dimension_7__tau_1                         0
    Adj Close__change_quantiles__f_agg_"var"__isabs_True__qh_1.0__ql_0.8    0
    Adj Close__fft_coefficient__attr_"real"__coeff_9                        0
    Adj Close__fft_coefficient__attr_"real"__coeff_8                        0
    Adj Close__fft_coefficient__attr_"real"__coeff_7                        0
    dtype: int64




```python
X = df_final.iloc[:, 5:].copy(deep=True)
y = df_final['target']
print(y[:3])
X.head(3)
```

    0    0
    1    0
    2    0
    Name: target, dtype: int64
    




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Adj Close</th>
      <th>Volume</th>
      <th>Adj Close__variance_larger_than_standard_deviation</th>
      <th>Adj Close__has_duplicate_max</th>
      <th>Adj Close__has_duplicate_min</th>
      <th>Adj Close__has_duplicate</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__abs_energy</th>
      <th>Adj Close__mean_abs_change</th>
      <th>Adj Close__mean_change</th>
      <th>...</th>
      <th>Volume__fourier_entropy__bins_2</th>
      <th>Volume__fourier_entropy__bins_3</th>
      <th>Volume__fourier_entropy__bins_5</th>
      <th>Volume__fourier_entropy__bins_10</th>
      <th>Volume__fourier_entropy__bins_100</th>
      <th>Volume__permutation_entropy__dimension_3__tau_1</th>
      <th>Volume__permutation_entropy__dimension_4__tau_1</th>
      <th>Volume__permutation_entropy__dimension_5__tau_1</th>
      <th>Volume__permutation_entropy__dimension_6__tau_1</th>
      <th>Volume__permutation_entropy__dimension_7__tau_1</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>19.593031</td>
      <td>1350600</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.952223</td>
      <td>8494.084498</td>
      <td>0.359854</td>
      <td>-0.015914</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.286836</td>
      <td>0.823959</td>
      <td>1.424130</td>
      <td>2.369382</td>
      <td>1.692281</td>
      <td>2.260234</td>
      <td>2.707270</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>1</th>
      <td>19.738565</td>
      <td>2432700</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>431.763572</td>
      <td>8486.601509</td>
      <td>0.351641</td>
      <td>0.006160</td>
      <td>...</td>
      <td>0.286836</td>
      <td>0.721464</td>
      <td>0.983088</td>
      <td>1.539654</td>
      <td>2.369382</td>
      <td>1.748067</td>
      <td>2.378620</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20.137426</td>
      <td>3323300</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>432.291793</td>
      <td>8507.596514</td>
      <td>0.335214</td>
      <td>-0.010267</td>
      <td>...</td>
      <td>0.450561</td>
      <td>0.721464</td>
      <td>1.098612</td>
      <td>1.539654</td>
      <td>2.484907</td>
      <td>1.735434</td>
      <td>2.406160</td>
      <td>2.813355</td>
      <td>2.833213</td>
      <td>2.772589</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 817 columns</p>
</div>




```python
y = df_final['target']
print(X.shape)
for fdr_level in [0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001, 0.0000005, 0.0000001]:
    df_filtered_binary = select_features(X, y, fdr_level=fdr_level, ml_task='classification')
    print(fdr_level, df_filtered_binary.shape)
```

    (5937, 817)
    0.05 (5937, 416)
    0.01 (5937, 371)
    0.005 (5937, 361)
    0.001 (5937, 341)
    0.0005 (5937, 331)
    0.0001 (5937, 313)
    5e-05 (5937, 311)
    1e-05 (5937, 296)
    5e-06 (5937, 292)
    1e-06 (5937, 286)
    5e-07 (5937, 282)
    1e-07 (5937, 277)
    


```python
y = df_final['delta_pct']

for fdr_level in [0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001, 0.0000005, 0.0000001]:
    df_filtered_reg = select_features(X, y, fdr_level=fdr_level, ml_task='regression')
    print(fdr_level, df_filtered_reg.shape)
```

    0.05 (5937, 399)
    0.01 (5937, 372)
    0.005 (5937, 361)
    0.001 (5937, 339)
    0.0005 (5937, 329)
    0.0001 (5937, 317)
    5e-05 (5937, 311)
    1e-05 (5937, 300)
    5e-06 (5937, 296)
    1e-06 (5937, 284)
    5e-07 (5937, 282)
    1e-07 (5937, 275)
    


```python
binary_cols = df_filtered_binary.columns.tolist()
reg_cols = df_filtered_reg.columns.tolist()
```


```python
both_cols = list(set(binary_cols+reg_cols))
```


```python
print(len(binary_cols), len(reg_cols), len(both_cols))
```

    277 275 288
    


```python
'Adj Close' in both_cols, 'Volume'in both_cols
```




    (True, True)




```python
y_cols = ['id', 'Date', 'target', 'delta_pct']
```


```python
df_final[y_cols + both_cols].head(3)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Date</th>
      <th>target</th>
      <th>delta_pct</th>
      <th>Volume__cwt_coefficients__coeff_11__w_20__widths_(2, 5, 10, 20)</th>
      <th>Volume__change_quantiles__f_agg_"mean"__isabs_True__qh_1.0__ql_0.8</th>
      <th>Adj Close__change_quantiles__f_agg_"mean"__isabs_False__qh_0.6__ql_0.2</th>
      <th>Volume__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)</th>
      <th>Adj Close__sum_values</th>
      <th>Adj Close__cwt_coefficients__coeff_13__w_20__widths_(2, 5, 10, 20)</th>
      <th>...</th>
      <th>Adj Close__cwt_coefficients__coeff_1__w_20__widths_(2, 5, 10, 20)</th>
      <th>Adj Close__cwt_coefficients__coeff_2__w_10__widths_(2, 5, 10, 20)</th>
      <th>Adj Close__minimum</th>
      <th>Adj Close__cwt_coefficients__coeff_0__w_10__widths_(2, 5, 10, 20)</th>
      <th>Volume__fft_coefficient__attr_"abs"__coeff_0</th>
      <th>Volume__cwt_coefficients__coeff_1__w_20__widths_(2, 5, 10, 20)</th>
      <th>Adj Close__cwt_coefficients__coeff_1__w_10__widths_(2, 5, 10, 20)</th>
      <th>Volume__cwt_coefficients__coeff_5__w_5__widths_(2, 5, 10, 20)</th>
      <th>Volume__mean</th>
      <th>Adj Close__linear_trend__attr_"slope"</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GSK</td>
      <td>2009-02-03</td>
      <td>0</td>
      <td>2.778513</td>
      <td>6.827091e+06</td>
      <td>320000.0</td>
      <td>-0.007189</td>
      <td>3.020586e+06</td>
      <td>431.952223</td>
      <td>66.731853</td>
      <td>...</td>
      <td>41.004967</td>
      <td>44.522909</td>
      <td>18.374868</td>
      <td>33.597595</td>
      <td>40175100.0</td>
      <td>3.762778e+06</td>
      <td>39.161548</td>
      <td>3.142434e+06</td>
      <td>1.826141e+06</td>
      <td>-0.084799</td>
    </tr>
    <tr>
      <th>1</th>
      <td>GSK</td>
      <td>2009-02-04</td>
      <td>0</td>
      <td>2.020719</td>
      <td>6.985642e+06</td>
      <td>320000.0</td>
      <td>-0.007189</td>
      <td>3.318212e+06</td>
      <td>431.763572</td>
      <td>66.577759</td>
      <td>...</td>
      <td>40.883390</td>
      <td>44.542326</td>
      <td>18.374868</td>
      <td>33.716539</td>
      <td>41702400.0</td>
      <td>4.073276e+06</td>
      <td>39.240166</td>
      <td>3.307973e+06</td>
      <td>1.895564e+06</td>
      <td>-0.079756</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GSK</td>
      <td>2009-02-05</td>
      <td>0</td>
      <td>-0.642376</td>
      <td>7.174840e+06</td>
      <td>320000.0</td>
      <td>-0.007189</td>
      <td>3.409041e+06</td>
      <td>432.291793</td>
      <td>66.449007</td>
      <td>...</td>
      <td>40.775041</td>
      <td>44.568357</td>
      <td>18.374868</td>
      <td>33.882053</td>
      <td>43462500.0</td>
      <td>4.166172e+06</td>
      <td>39.343889</td>
      <td>3.367270e+06</td>
      <td>1.975568e+06</td>
      <td>-0.073900</td>
    </tr>
  </tbody>
</table>
<p>3 rows × 292 columns</p>
</div>




```python
file_name = 'PFE_GSK_final.csv'
df_final[y_cols + both_cols].to_csv('data/'+file_name, sep='|', compression='gzip')
```
